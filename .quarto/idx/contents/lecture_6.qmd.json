{"title":"Chapter 6. Decision making under uncertainty","markdown":{"yaml":{"title":"Chapter 6. Decision making under uncertainty","author":{"name":"My Dam","email":"my-thi-tra.dam@universite-paris-saclay.fr"},"number-sections":true,"execute":{"echo":false,"warning":false},"format":{"html":{"toc":true,"toc-depth":3,"toc-title":"Content","toc-location":"left"}}},"headingText":"from IPython.display import display","containsRefs":false,"markdown":"\n\n\n```{python}\n%load_ext autoreload\n%autoreload 2\n```\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns\nimport pandas as pd\nimport dataframe_image as dfi\nimport ipywidgets as widgets\n# from ipywidgets import interact\nimport pandas as pd\n```\n\n```{python}\nimport sys\nimport os\nmod_dir = os.path.join(os.getcwd(), 'modules')\nif mod_dir not in sys.path:\n    sys.path.append(mod_dir)\n\nimport micro_modules as mm\nmm.load_viz_settings()\n```\n\n```{python}\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n```\n\nLife abounds with uncertainty, which can be viewed as danger or oppotunities. Pandemics are bad. Wars are bad. But if one has the guts to enter the market during the bear, she will be amply rewarded once it gets to the bull. \nIf there were no uncertainty, there would be no bets. Many games and financial products would not have existed. Investment opportunities range from the high risk type, such as startups, cryptocurrencies, leveraged positions in equity trading to safer ones such as highly rated government bonds. We buy insurance to protect ourselves from the risk of sickness. We save _more_ when we are uncertain about the future. Much of the human evolution has been marked with our species' ingenuity in adapting to and thriving in uncertain environments. Making decisions under uncertainty is often hard, especially when the uncertainty is not quantifiable[^1]. In this chapter, we will be mainly intererested in quantifiable uncertainty or risk, situations in which the decision-maker knows the underlying probability distribution of the random variable of interest (such as future earnings or losses due to sickness). Often times it is hard to make a choice based on pure calculation. Anyone who has ever invested knows that emotion plays no small role in our ability to succeed in a volatile environment.\n\n[^1]: A situation known as ambiguity or Knightian uncertainty. Under ambiguity, unlike under risk, the decision-maker does not know the probability law underlying the random variable of interest. Sometimes in the vernacular, risk is referred to as the _known unknown_ and ambiguity as the _unknown unknown_. Even though they are both uncertainty, ambiguity has been documented to result in higher cognitive load than risk because while risk is processed by the rational powerhouse of our brain, the prefrontal cortex, ambiguity tends to trigger fear and anxiety which are associated with the amygdala in our brain.\n\n# Lotteries\n\nThe simplest way to model an uncertain prospect is by means of a lottery. \n\n::: {#def-lottery}\n## Lottery\nA simple loterry is a list of probabilities over a finite set of consequences or prizes. In particular let $C=\\{c_1,c_2,\\dots,c_N\\}$ be the set of consequences and $p_n$ be the probability that $c_n$ is realized. Then the simple lottery $L$ over the set $C$ is:\n$$\nL = \\{p_1,p_2,\\dots,p_N\\},\n$${#eq-lottery}\n\nwhere $p_i = P(X=c_i)$ satisfying $p_i\\ge 0$ for all $i=1,...,N$ and $\\sum_{i=1}^N p_i = 1.$\n:::\n\n::: {#rem-altDef}\nIn some textbooks a lottery is defined as a list of consequence-probability _pairs_ instead of just a list of probabilities.\n:::\n\nA lottery with $p_i=1$ for some $i$ is called a *degenerated* lottery.\n\n::: {#def-simplex}\n## Simplex\nThe simplex or probability simplex of lotteries, denoted by $\\mathcal{L}$ (or $\\Delta$) is the set of all simple lotteries over a set of outcomes:\n$$\n\\mathcal{L} = \\{p \\geq 0: \\sum_{i=1}^N p_i = 1\\}.\n$$\n:::\n\nSometimes the prizes are lotteries themselves. Lotteries over such prizes are called compound lotteries.\n\n::: {#def-compoundLottery}\n## Compound lottery\nLet $(L_1, L_2, ... L_K)$ be simple lotteries over the same set of prizes (i.e., $L_k\\in \\Delta$ for all $k=1,...,K.$) Let $\\alpha_k$ be the probability of obtaining $L_k.$ Then the compound lottery can be written as:\n$$\n(L_1,L_2,\\dots,L_K;\\alpha_1,\\alpha_2,\\dots,\\alpha_K).\n$$\n:::\n\nNote that any compound lottery can be reduced to a simple lottery:\n$$\nL = \\sum_{k=1}^K \\alpha_k L_k.\n$${#eq-comp_to_red}\n\nAccording to the __consequentialist hypothesis__, only consequences and the probability associated to each consequence matters; the route through which a consequence is obtained is irrelevant. If you have taken a course in probability, you know that this is just the law of total probability. \n\n::: {#fig-compoundLottery fig-cap=\"A compound lottery and its reduced simple lottery\"}\n\n```{python}\n# Initialize figure and axis\nfig, ax = plt.subplots(figsize=(6, 8), nrows=2, ncols=1)\n\n# root\nax[0].scatter(0, 0, color='k', s=75)\n\n# Plot the lines\nax[0].plot([0, 1.5], [0, 1.5], 'k-', lw=3, alpha=.5)  \nax[0].plot([0, 1.5], [0, 0], 'k-', lw=3, alpha=.5)  \nax[0].plot([0, 1.5], [0, -1.5], 'k-', lw=3, alpha=.5) \n\n# Add the text annotations for α and L\nax[0].text(1.55, 1.5, r'$L_1 = (1, 0, 0)$', fontsize=14, ha='left')\nax[0].text(1.55, 0, r'$L_2 = \\left( \\frac{1}{4}, \\frac{3}{8}, \\frac{3}{8} \\right)$', fontsize=14, ha='left')\nax[0].text(1.55, -1.5, r'$L_3 = \\left( \\frac{1}{4}, \\frac{3}{8}, \\frac{3}{8} \\right)$', fontsize=14, ha='left')\n\n# Add the text annotations for α\nax[0].text(0.6, 0.75, r'$\\alpha_1 = \\frac{1}{3}$', fontsize=14, rotation=36, va='bottom',\nha='left')\nax[0].text(0.7, 0.2, r'$\\alpha_2 = \\frac{1}{3}$', fontsize=14, ha='left')\nax[0].text(0.6, -0.75, r'$\\alpha_3 = \\frac{1}{3}$', fontsize=14, va='top', ha='left', rotation=-36)\n\n# Set limits and remove axes\nax[0].set_xlim(-0.1, 2.5)\nax[0].set_ylim(-2, 2)\nax[0].set_title(\"Compound lottery\")\nax[0].axis('off')  # Turn off the axis\n\n\n\n# Second plot\n# root\nax[1].scatter(0, 0, color='k', s=75)\n\n# Plot the lines\nax[1].plot([0, 1.5], [0, 1.5], 'k-', lw=3, alpha=.5)  \nax[1].plot([0, 1.5], [0, 0], 'k-', lw=3, alpha=.5)  \nax[1].plot([0, 1.5], [0, -1.5], 'k-', lw=3, alpha=.5) \n\n# Add the text annotations for α and L\nax[1].text(1.55, 1.5, r'$c_1$', fontsize=14, ha='left')\nax[1].text(1.55, 0, r'$c_2$', fontsize=14, ha='left')\nax[1].text(1.55, -1.5, r'$c_3$', fontsize=14, ha='left')\n\n# Add the text annotations for α\nax[1].text(0.6, 0.75, r'$p_1 = \\frac{1}{2}$', fontsize=14, rotation=36, va='bottom',\nha='left')\nax[1].text(0.7, 0.2, r'$p_2 = \\frac{1}{4}$', fontsize=14, ha='left')\nax[1].text(0.6, -0.75, r'$p_3 = \\frac{1}{4}$', fontsize=14, va='top', ha='left', rotation=-36)\n\n# Set limits and remove axes\nax[1].set_xlim(-0.1, 2.5)\nax[1].set_ylim(-2, 2)\n\nax[1].set_title(\"Reduced (simple) lottery\")\n\n# Show the plot\nplt.axis('off')\nplt.show()\n```\n:::\n\n# Preferences over lotteries\n\nLet $C$ be the set of outcomes (consequences) and $\\mathcal{L}$ the set of all simple lotteries over $C$\n\nA preference relation $\\succeq$ over $\\mathcal{L}$ is said to satisfy:\n\n1. __Completeness__ if for any $L, L' \\in \\mathcal{L}$, either $L\\succeq L'$ or $L'\\succeq L$ or both\n\n2. __Transitivity__ if for any $L, L', L'' \\in \\mathcal{L}$, if $L\\succeq L'$ and $L' \\succeq L''$ then $L\\succeq L''.$\n\n3. __Continuity__ if for $L, L' \\in \\mathcal{L}$ such that $L\\succ L'$, there are neighborhoods $B(L)$ of $L$ and $B(L')$ of $L'$ such that for all $L_a \\in B(L)$ and $L_b \\in B(L')$, the direction of preference is preserved: $L_a \\succ L_b.$ Intuitively, this means that if one strictly prefers a lottery to another, then a slight modification of the lotteries will not alter her ranking.\n\n4. __Independence axiom (IA)__ if for any $L, L', L'' \\in \\mathcal{L}$ and $\\alpha \\in (0,1)$:\n    $$\n    L\\succeq L' \\iff \\alpha L + (1-\\alpha)L'' \\succeq \\alpha L' + (1-\\alpha)L''.\n    $${#eq-IA}\n\n    Intuitively, this means that if one prefers a lottery to another then mixing each by the same proportion with a third lottery will not alter the preference ordering.\n\n# Expected utility theory\n\n::: {#def-EU}\n## Expected utility\nThe utility function $U:\\mathcal{L} \\to \\mathbb{R}$ has the expected utility form if there exist an assignment of numbers $(u_1, ..., u_N)$ to the $N$ possible outcomes such that for every simple lottery $L=(p_1,..., p_N) \\in \\mathcal{L}$, we have:\n$$\nU(L) = \\sum_{n=1}^N p_n u_n.\n$${#eq-EU_form}\n:::\n\nIn other words, $U$ has an expected utility form if there exists some utility function $u:\\mathbb{R}\\to\\mathbb{R}$ that assigns $u_i$ to each consequence $i$ of the lottery $L.$ If such a representation exists, then $U$ is referred to as the von-Neumann Morgenstern (vNM) utility function. We can then compare lotteries by computing the expected utilities associated with them. When does such a representation exist? \n\n::: {#thm-reprsentation}\n## Representability\nIf a decision-maker's preferences over lotteries satisfy completeness, transitivity, continuity and the independence axiom, then it has an expected utility reprsentation. \n:::\n\nObserve that if an expected utility representation exists, then comparing lotteries is equivalent to comparing expected utilities derived from lotteries.\n\n\nSince $U$ is essentially a mathematical expectation, it is a linear map, i.e., let $(L_1,\\dots,L_K;\\alpha_1,\\dots,\\alpha_K)$ be a compound lottery, then:\n\n$$\nU\\left(\\sum_{k=1}^K L_k\\right) = \\sum_{k=1}^K U(L_k).\n$${#eq-linearity-of-U}\n\nAnother way to see this is to observe that the term inside the brackets on the LHS, by the consequentialist assumption, is a simple lottery:\n\n$$\nL = \\left(\\sum_{k=1}^K \\alpha_k p^k_1, \\sum_{k=1}^K \\alpha_k p^k_2, \\dots, \\sum_{k=1}^K \\alpha_k p^k_N\\right)\n$$\n\nover the set of outcomes $(u_1,u_2,\\cdots,u_N),$ where $p^k_i$ denotes the probability of $u_i$ under lottery $k.$ We can think of $\\sum_{k=1}^K \\alpha_k p^k_i$ as the average probability of $u_i$ across $K$ lotteries ($K$ different scenarii).\n\nWe can then rewrite the LHS as:\n\n$$\nU\\left(\\sum_{k=1}^K \\alpha_k L_k\\right) = U(L) = \\sum_{i=1}^N \\sum_{k=1}^K \\alpha_k p^k_i u_i.\n$${#eq-LHS-temp}\n\nThe RHS of @eq-linearity-of-U can be written as:\n\n$$\n\\sum_{k=1}^K \\alpha_k \\sum_{i=1}^N p^k_i u_i,\n$$\n\nwhich is equivalent to @eq-LHS-temp.\n\nAnother important property of the vNM utility is that it is **cardinal**, i.e., the value of the function $U:\\mathcal{L} \\to \\mathbb{R}$ is not just used for ranking; it also has a meaning. It is thus defined only up to a positive affine transformation, i.e., if $U$ reprsents the preferences $\\succeq$ over the lotteries then so is $aU + b$ for $a>0$ and $b\\in\\mathbb{R}.$ This is in contrast to the ordinal utility function introduced in the first chapter, which is preserved under any positive monotone transformation.\n\n# Indifference curves\n\nHow do indifference curves (IC) look like for preferences over lotteries? They must be **straight lines** and are **parallel** to one another.\n\nWhy straight lines? Suppose $L$ and $L'$ lie on the same IC, i.e., $L \\sim L'.$ By the IA, if we mix $L$ and $L'$ with the same lottery by the same proportion, our preference ranking would remain unchanged. Mathematically for any $\\alpha\\in[0,1]:$\n\n$$\n\\begin{aligned}\nL &\\sim L' \\\\\n\\alpha L + (1-\\alpha)L &\\sim \\alpha L' + (1-\\alpha)L \\\\\nL &\\sim \\alpha L' + (1-\\alpha)L. \n\\end{aligned}\n$$\n\nIn other words, if we fix any two lotteries on the same IC, then any convex combination between them (the line connecting the two lotteries) must lie on the same IC. Since $L$ and $L'$ can be arbitrarily chosen, it follows that an IC must be a straight line. \n\nWhy must ICs be parallel to one another? Suppose by contrast there exist two indifference curves $IC_1$ and $IC_2$ intersecting at some lottery $L.$ Let $L_1$ be a lottery on $IC_1$ and $L_2$ be a lottery on $IC_2$ and WLOG suppose that $U(L_2) > U(L_1).$ Now $L \\in IC_1$ hence $U(L)=U(L_1).$ But $L \\in IC_2$ implying $U(L)=U(L_2) > U(L_1) = U(L),$ a contradiction. Hence no two ICs can intersect.\n\n# Money lotteries\n\nWe now consider a more general space of consequences $C=\\mathbb{R}.$ In other words, the outcomes are a continuous variables. The lottery will thus be the probability law underlying some continuous random variable $X.$ In particular we define money lotteries by means of the cdf of $X,$ that is $F:\\mathbb{R}\\to[0,1]$ defined by:\n\n$$\nF(x) = Pr(X \\leq x), \\quad x \\in \\mathbb{R}.\n$$\n\nFrom probability theory we know that a random variable is characterized by its cdf. The same reduction principle applies to compound lotteries. In particular, let $F_1(x), F_2(x),\\dots,F_K(x)$ be $K$ simple money lotteries, each with probability $\\alpha_k$ of occurence. Then the compound lottery can be represented as:\n$$\nF(x) = \\sum_{k=1}^K \\alpha_k F_k(x).\n$${#eq-compound-money-lot}\n\nWe now consider positive monetary amounts, letting $C=\\mathbb{R}_+.$ The expected utility derived from the lottery $F(x)$ of a decision-maker whose preferences admit an expected utility representation is:\n\n$$\nU(F) \\equiv \\mathbb{E}[u(X)] = \\int u(x) dF(x) = \\int u(x)f(x)dx,\n$${#eq-EU-cont-case}\n\nwhere $f:\\mathbb{R}\\to\\mathbb{R}_+$ is the pdf of $X,$ if it exists (i.e. if the cdf is [absolutely continuous](https://en.wikipedia.org/wiki/Absolute_continuity)), and $u(x)$ is the utility obtained from $x$ dollars. The function $u$ is assumed to be continuous, increasing and bounded.[^2] It is often referred to as the Bernoulli utility function.\n\n[^2]: Boundedness is needed to rule out the St.Petersburg paradox.\n\n::: {#exm-MVutility}\n## Mean-variance utility\nLet $u:\\mathbb{R}_+\\to\\mathbb{R}$ be defined by $u(x)=\\beta x^2 + \\gamma x,$ where $\\gamma >0, \\: \\beta < 0$ and $F$ the cdf of $X.$ Then:\n$$\n\\begin{aligned}\n\\mathbb{E}u(X) = U(F) &= \\int u(x) dF(x) \\\\\n&= \\int(\\beta x^2 + \\gamma x) dF(x) \\\\\n&= \\beta \\int x^2 dF(x) + \\gamma \\int x dF(x) \\\\\n&= \\beta \\sigma^2_X + \\gamma \\mu_x + \\beta \\mu_x^2,\n\\end{aligned}\n$$\n\nwhere $\\sigma^2_X$ and $\\mu_X$ are the variance and mean of $X,$ respectively. Thus the expected utility derived from $X$ depends only on the mean and the variance of $X,$ i.e., only on the first two moments of this random variable.[^3]\n\n[^3]: Observe that this utility function is increasing only for $x \\geq -2\\beta/\\gamma.$\n:::\n\n# Risk preferences\n\n## Three preferences towards risk\n\nLet $X$ be a positive-valued random variable that an individual receives. We say that she is **risk-averse** (or exhibits risk aversion) if:\n\n$$\n\\mathbb{E}[u(X)] \\leq u(\\mathbb{E}[X]).\n$${#eq-RA-def}\n$$\n\\int u(x)dF(x) \\leq u\\left(\\int x dF(x)\\right).\n$${#eq-RA-def2}\n\nIf the inequality ([-@eq-RA-def]) or ([-@eq-RA-def2]) reverts, then the individual is **risk-loving**. If the inequality sign becomes an equality, she is **risk-neutral**. Mathematically, risk aversion is captured by a concave Bernoulli utility function $u$, risk loving by a convex  and risk neutrality by a linear Bernoulli utility function respectively.\n\nIntuitively, someone who dislikes risk would prefer a sure gain equivalent to the mean of a random variable rather than playing the lottery over the outcomes of the random variable. \n\n::: {#exm-risk-aversion}\nConsider a game in which one is proposed two options. In the first option, she can either win nothing or \\$10,000 with equal probabilities (by tossing a fair coin, for example). In the second, she can walk away with \\$5000 for sure. Which option will she choose? If she is (strictly) risk-averse, then she will (strictly) prefer the second. If risk-loving, she will prefer the first. If risk-neutral, she will be indifferent.\n\n::: {#fig-ra-exm fig-cap=\"Choices between lotteries and risk preferences\"}\n:::: {.columns}\n::: {.column width=\"45%\"}\n```{mermaid}\nflowchart TB\n    opt1[Option 1] -- 0.5 --> $10000\n    opt1 -- 0.5 --> $0\n```\n:::\n\n::: {.column width=\"45%\"}\n```{mermaid}\nflowchart TB\n    opt2[Option 2] -- 1 --> $5000\n```\n:::\n::::\n:::\n\n:::\n\n## Certainty equivalent and risk premium\n\nBeing strictly risk averse implies that the individual strictly prefers a sure gain to a lottery of the same mean. By continuity, this implies there exists a smaller sure gain that makes the individual indifferent between this smaller sure gain and the lottery. This amount is called the __certainty equivalent__ of the lottery.\n\n::: {#def-CE}\n## Certainty equivalent\nLet $X$ be a positive-valued continuous random variable with cdf $F:\\mathbb{R}_+\\to [0,1].$ Consider a decision-maker whose risk preferences is represented by continuous, strictly increasing and bounded utility function $u:\\mathbb{R}_+\\to\\mathbb{R}.$ The certainty equivalent of $F$ for this decision-maker is:\n$$\n\\begin{aligned}\nc(u, F) &= u^{-1}\\left(U(F)\\right) \\\\\n&=u^{-1}\\left(\\int u(x) dF(x)\\right).\n\\end{aligned}\n$$\n:::\n\nNote that the CE is monetary amount. Clearly the CE is smaller/equal/greater than the mean of the monetary random variable if the decision-maker is risk-averse/neutral/loving. The difference between the CE and the mean of the random monetary prize is called the __risk premium__, which is positive if and only if the decision-maker is risk-averse.\n\n::: {#def-RP}\n## Risk premium\nThe risk premium is the maxmium amount that a decision maker is willing to pay eliminate risk, i.e., to be indifferent between receving the sure gain equal to the mean prize and the lottery. Mathematically,\n$$\n\\begin{aligned}\nRP(u, F) &= EV - c(u, F) \\\\\n&= \\int x dF(x) - c(F, u) \\\\\n&= \\int x dF(x) - u^{-1}\\left(\\int u(x) dF(x)\\right).\n\\end{aligned}\n$${#eq-riskPrem}\n:::\n\nSometimes we denote the risk premium by $\\pi.$ Let us illustrate these two important concepts graphically.\n\n::: {#fig-CEandRP fig-cap=\"Certainty equivalent and risk premium\"}\n\n```{python}\nfrom matplotlib.patches import FancyArrowPatch\nx = np.linspace(0.05, 20, 250)\nprobs = np.array([1 / 3, 2 / 3])\nprizes = np.array([0.1, 12])\na = 1 / 5\ndef vlines(x, ymax):\n    plt.vlines(x=x, ymin=0, ymax=ymax, linestyle='--', lw=0.5, color='gray')\ndef hlines(y, xmax):\n    plt.hlines(y=y, xmin=-2, xmax=xmax, linestyles='--', lw=0.5, color='gray')\ndef u(x, a):\n    return x ** a\ndef EU(prob, prize):\n    return np.dot(prob, u(prize, a))\ndef CE(u_expected):\n    return u_expected ** (1 / a)\ndef EV(prob, prize):\n    return np.dot(prob, prize)\n# plt.figure(figsize=(5, 4))\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.plot(x, u(x, a), color='k')\nplt.plot(prizes, u(prizes, a), color='gray', linestyle='--', lw=1.5)\nu1, u2 = u(prizes, a)\nev = EV(probs, prizes)\neu = EU(probs, prizes)\nce = CE(eu)\nvlines(x=prizes[0], ymax=u1)\nvlines(x=prizes[1], ymax=u2)\nhlines(y=u1, xmax=prizes[0])\nhlines(y=u2, xmax=prizes[1])\nvlines(x=ev, ymax=u(ev, a))\nhlines(y=eu, xmax=ev)\nhlines(y=u(ev, a), xmax=ev)\nvlines(x=ce, ymax=eu)\n\n# annotations\n# x-axis\nplt.text(prizes[0]*.95, -0.1, '$x_1$')\nplt.text(prizes[1]*.95, -0.1, '$x_2$')\nplt.text(ev*.95, -0.1, '$E[X]$')\nplt.text(ce*.95, -0.1, '$c(u,F)$')\n# y-axis\nplt.text(-3.5, u1, '$u_1$')\nplt.text(-3.5, u2, '$u_2$')\nplt.text(-2.5, eu, '$E[u(X)]$', ha='right')\nplt.text(-2.5, u(ev, a), '$u(E[X])$', ha='right')\n# risk premium\nriskprem = ce - ev\narrow = FancyArrowPatch(\n    posA=(ce, u1/2), posB=(ev, u1/2), arrowstyle='<->',\n    color='red', mutation_scale=10)\nax.add_patch(arrow)\nplt.text((ce + ev)/2, u1/2 * 1.1, 'RP')\n# u(x)\nplt.text(1.25*prizes[1], u2, \"$u(x)$\")\n\nplt.xlim([-2, x.max()])\nplt.ylim([0, u2 * 1.1])\nplt.xlabel('Money', loc='right')\nplt.ylabel('Utility')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```\n:::\n\n## Measure of risk aversion\n\nThere are two common measures of risk aversion: the (Arrow-Pratt) coefficient of absolute risk aversion and coefficient of relative risk aversion. \n\n::: {#def-ARAandRRA}\n## Absolute and relative risk aversion\nThe Arrow-Pratt coefficient of absolute risk aversion for a decision maker with Bernoulli utility function $u:\\mathbb{R}_+\\to\\mathbb{R}$ is:\n$$\nA(x) = -\\frac{u''(x)}{u'(x)}.\n$${#eq-coefARA}\nThe coefficient of _relative risk aversion_ for the same decision-maker is:\n$$\nR(x) = - \\frac{u''(x)x}{u'(x)}.\n$${#eq-coefRRA}\n:::\n\nWhy don't we just use the convexity of $u,$ namely the second derivative of $u?$ Because this measure has an undesirable property: it is not invariant to a positive linear transformation of $u.$ \n\n::: {#exm-utilityFunctions}\n## CARA utility\nThe following utility satisfies constant absolute risk aversion\n$$\nu(x) = -e^{-ax},\n$${#eq-CARAutility}\nwhere $a>0$ is the coefficient of absolute risk aversion.\n:::\n\n::: {#exm-utilityFunctions}\n## CRRA utility\nThe following utility satisfies constant relative risk aversion\n$$\nu(x) = \\begin{cases}\n    \\frac{x^{1-\\sigma}-1}{1-\\sigma}, & \\sigma \\neq 1 \\\\\n    \\ln (x), & \\sigma = 1.\n\\end{cases}\n$${#eq-CRRAutility}\nThe coefficient of constasnt relative risk aversion is $R(x)=\\sigma.$ Note that the vNM utility function is _homothetic_ if and only if the Bernoulli utility function is satisfies CRRA.\n:::\n\n::: {#fig-cara fig-cap=\"CARA utility function and increasing absolute risk aversion\"}\n```{python}\na = [.25, .5, 2.]\nx = np.linspace(0, 20, 250)\ndef cara(x, a):\n    return -np.exp(-a*x)\n# fig, ax = plt.subplots(figsize=(5, 5))\nfor i in a:\n    plt.plot(x,  cara(x, i), label=f'$A(x)=a={i}$')\nplt.title(r\"$u(x)=-e^{-ax}$\")\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$u(x)$\")\nplt.legend()\nplt.xticks(np.linspace(0, 20, 5))\n# plt.grid(None)\nplt.show()\n```\n:::\n\n# Comparing payoff distributions\n\nThe previous section compares different attitudes towards risk (uncertain payoffs). We now compare distributions of payoff (lotteries) using the concept of __stochastic dominance__.\n\n## First order stochastic dominance (FOSD)\n\n::: {#def-FSD}\n## FOSD\nLottery $F$ is said to first order stochastically dominate (FOSD) lottery $G$ if for all payoff $x$:\n$$\nF(x) \\leq G(x).\n$$\n:::\n\nIntuitively, the stochastically dominant lottery concentrates more probability weight on higher payoff values. Graphically, $F$ FOSD $G$ if $F$ is below $G$. \n\n::: {#exm-FSD}\nSuppose $X\\sim U(0,1)$ and $Y\\sim U(0,2).$ Denote the cdf of $X$ by $F_X$ and the cdf of $Y$ by $F_Y.$ Then $F_Y$ FOSD $F_X.$ Indeed, the cdf of a $U(a,b)$ random variable is given by:\n$$\nF(x) = \\begin{cases}\n    0 & x < a \\\\\n    \\frac{x - a}{b - a} & x \\in [a, b] \\\\\n    1 & x > b.\n\\end{cases}\n$${#eq-Ucdf}\nHence\n$$\nF_X(x) = \\begin{cases}\n    0 & x < 0 \\\\\n    x & x \\in [0, 1] \\\\\n    1 & x > 1.\n\\end{cases}\n$$\nand\n$$\nF_Y(x) = \\begin{cases}\n    0 & x < 0 \\\\\n    \\frac{x}{2} & x \\in [0, 2] \\\\\n    1 & x > 2.\n\\end{cases}\n$$\n\nClearly $F_Y(x) \\leq F_X(x)$ for all $x,$ implying that $F_Y$ FOSD $F_X.$\n\n::: {#fig-FSDUnif fig-cap=\"FOSD of $U(0,2)$ over $U(0,1)$\"}\n```{python}\nx = np.linspace(0, 1, 100)\ny = np.linspace(0, 2, 100)\ndef Fx(x, a, b):\n    return (x - a) / (b - a)\ndef plotcdf(x, a, b, color, alpha=.5, lw=2):\n    cdf_vals = Fx(x, a, b)\n    plt.plot(x, Fx(x, a, b), color=color, lw=lw, label=f'U({a},{b})', alpha=alpha)\n    plt.hlines(y=1, xmin=b, xmax=3, color=color, lw=lw, alpha=alpha)\n    plt.hlines(y=0, xmin=-2, xmax=a, color=color, lw=lw, alpha=alpha)\n    plt.legend()\n# plt.figure(figsize=(5, 5))\nplotcdf(x, 0, 1, 'k', lw=3.5)\nplotcdf(y, 0, 2, 'red', lw=3)\nplt.grid(None)\nplt.show()\n```\n:::\n:::\n\n## Second order stochastic dominance (SOSD)\n::: {#def-SOSD}\n## SOSD\nLottery $F$ is said to second order stochastically dominate lottery $G,$ denoted $F$ SOSD $G,$ if they have the same mean and for every nondecreasing concave utility function $u:\\mathbb{R}\\to\\mathbb{R},$ the expected utility under $F$ is greater than that under $G.$ Mathematically:\n\n$$\n\\begin{aligned}\n\\mathbb{E}_F[X] &= \\mathbb{E}_G[X], \\\\\n\\mathbb{E}_F [u(X)] &\\geq \\mathbb{E}_G[u(X)].\n\\end{aligned}\n$$\nor equivalently:\n$$\n\\begin{aligned}\n\\int x dF(x) &= \\int x dG(x), \\\\\n\\int u(x) dF(x) &\\geq \\int u(x) dG(x).\n\\end{aligned}\n$$\n:::\n\n::: {#rem-SOSD-inv-rule}\nNote that the inequality condition in @def-SOSD can be shown to be equivalent to:\n$$\n\\int_a^x [G(t) - F(t)]dt \\geq 0,\\quad x \\in [a,b].\n$${#eq-SOSD-alt-cond}\n:::\n\n::: {#exm-SOSD}\n## Mean-preserving spread\nConsider again two random payoffs $X$ and $Y$ where $X\\sim U(a,b)$ and $Y\\sim U(a-\\epsilon,b+\\epsilon),$ where $b>a>0$ and $\\epsilon >0.$ Observe that both $X$ and $Y$ have the same mean equal to $(b-a)/2$ but the distribution of $Y$ is more spread out about the mean compared to that of $X.$ We say that the distribution of $Y$ is obtained by a mean-preserving spread of the distribution of $X,$ hence is riskier. Let us show that $F_X$ SOSD $F_Y.$ Denote $f_X$ and $f_Y$ the pdfs of $X$ and $Y,$ respectively. Note that:\n$$\n\\begin{aligned}\nf_X(x) &= \\frac{1}{b-a}\\mathbb{1}_{x\\in[a,b]}, \\\\\nf_Y(x) &= \\frac{1}{b-a+2\\epsilon}\\mathbb{1}_{x\\in[a-\\epsilon,b+\\epsilon]},\n\\end{aligned}\n$$\nwhere $\\mathbb{1}_{x\\in[c,d]}$ is an indicator function taking value of one if $x\\in[c,d]$ and zero otherwise. \nIt is easy to check that the cdfs of $X$ and $Y$ can be written as follows:\n$$\nF_X(x) = \\begin{cases}\n    0 & x < a \\\\\n    \\frac{x-a}{b-a} & x \\in [a, b] \\\\\n    1 & x > b.\n\\end{cases}\n$$\nand\n$$\nF_Y(x) = \\begin{cases}\n    0 & x < a-\\epsilon \\\\\n    \\frac{x-a+\\epsilon}{b-a+2\\epsilon} & x \\in [a-\\epsilon,b+\\epsilon] \\\\\n    1 & x > b+\\epsilon.\n\\end{cases}\n$$\nWe will be proving SOSD using ([-@eq-SOSD-alt-cond]). In particular, we only need to verify this condition for $x\\in[a,b],$ namely:\n$$\n\\int_{a}^x [F_Y(t) - F_X(t)] dt \\geq 0,\\quad \\forall x\\in[a,b].\n$$\nIndeed:\n$$\n\\begin{aligned}\nF_Y(t) - F_X(t) &= \\frac{x-a-\\epsilon}{b-a+2\\epsilon} - \\frac{x-a}{b-a} \\\\\n&=\\frac{\\epsilon (a+b-2t)}{(b-a+2\\epsilon)(b-a)} \\\\\n\\implies \\int_{a}^x [F_Y(t) - F_X(t)] dt &= \\frac{\\epsilon}{(b-a+2\\epsilon)(b-a)}\\left[(a+b)x - x^2\\right]_a^x \\\\\n&= \\frac{\\epsilon}{(b-a+2\\epsilon)(b-a)}(x-a)(b-x) \\\\\n&\\geq 0,\n\\end{aligned}\n$$\nwhere the last inequality holds strictly for $x\\in(a,b).$\n:::\n\n## Other measures of stochastic dominance\n\nLet $X$ be a random variable (such as monetary payoffs). Let $F$ and $G$ are two cdfs over the support of $X$. Suppose also that the pdf associated with $F$ and $G$ exist and are denoted by $f$ and $g,$ respectively.\n\n### Hazard rate dominance (HRD)\n\nThe hazard rate of a lottery $F$ is given by:\n\n$$\nHR_F(x) = \\frac{f(x)}{1 - F(x)}.\n$${#eq-hazard-rate}\n\nIntuitively, the hazard rate is the conditional density of $X$ given the probability of the payoff exceeding $x.$\n\nWe say that $F$ dominates $G$ in terms of the hazard rate if:\n\n$$\nHR_F(x) \\leq HR_G(x), \\quad \\forall x.\n$${#eq-hazard-rate-dom}\n\n::: {#exr-HRD}\nShow that HRD implies FOSD.\n:::\n\n### Reverse hazard rate dominance (RHRD)\n\nThe reverse hazard rate of a lottery $F$ is given by:\n\n$$\nRHR_F(x) = \\frac{f(x)}{F(x)}.\n$${#eq-rev-hazard-rate}\n\nIntuitively, the reverse hazard rate is the conditional density of $X$ given the probability of the payoff being less than $x.$\n\nWe say that $F$ dominates $G$ in terms of the reverse hazard rate if:\n\n$$\nHR_F(x) \\geq HR_G(x), \\quad \\forall x.\n$${#eq-rev-hazard-rate-dom}\n\n::: {#exr-RHRD}\nShow that RHRD implies FOSD.\n:::\n\n### Likelihood ration dominance (LRD)\n\nWe say that $F$ dominates $G$ in terms of the likelihood ratio if:\n\n$$\n\\frac{f(x)}{g(x)} \\leq \\frac{f(y)}{g(y)}, \\quad \\forall x < y.\n$${#eq-LRD}\n\n::: {#exr-LRD}\nShow that LRD implies HRD.\n:::\n\nHence LRD is a very strong notion of stochastic dominance, it implies HRD which in turn implies FOSD.\n\n# Paradoxes and alternative theories\n\n## Allais's paradox \n\nThe Allais's paradox illustrates the violation of the independence axiom (IA).\nConsider the set of prizes $C=\\{\\$2.5M, \\$0.5M, 0\\}$ and two lotteries over $C:$\n$$\nL_1 = (0, 1, 0), \\quad L_1'=\\left(\\frac{10}{100}, \\frac{89}{100}, \\frac{1}{100}\\right).\n$${#eq-allais_choice1}\n    \nMost respondents in controlled experiments will choose $L_1,$ which gives a sure prize of 0.5M:\n$$\nL_1 \\succ L_1'\\iff u_{0.5} > \\frac{10}{100}u_{2.5} + \\frac{89}{100}u_{0.5} + \\frac{1}{100}u_{0}.\n$${#eq-allais_1}\n    \n    \nNow consider the same set of outcomes but two other lotteries: \n$$\nL_2=\\left(0, \\frac{11}{100}, \\frac{89}{100}\\right), \\quad \nL_2'=\\left(\\frac{10}{100}, 0, \\frac{90}{100}\\right).\n$${#eq-allais_choice2}\n\nMost people strictly prefer $L_2'$ over $L_2.$\nBy the IA if we add $\\frac{89}{100}u_0 - \\frac{89}{100}u_{0.5}$ to both sides of @eq-allais_1 we should preserve the direction of the inequality, this yields:\n$$\n\\frac{11}{100}u_{0.5} + \\frac{89}{100}u_{0} > \\frac{10}{100}u_{5} + \\frac{90}{100}u_{0}.\n$$  \nBut a strict preference of $L_2'$ over $L_2$ implies:\n$$\\frac{10}{100}u_{5} + \\frac{90}{100}u_{0} > \\frac{11}{100}u_{0.5} + \\frac{89}{100}u_{0}, \n$$\na contradiction.\n\nOne explanation for this paradox is the unrealistic values of probabilities presented, which are close to one or zero and hence are rarely encountered in practice. Another justification comes from _regret theory_, according to which individuals do not wish to regret a sure win.\n\n## Ellsberg's paradox and ambiguity aversion\n\nIn real life situations, we often have to form some probabilistic judgement while making a decision. In tossing a fair coin, we know that the probability of obtaining either results is one half. But in predicting the probability of a presidential candidate winning, we often need to form some subjective evaluation. One nice thing about subjective probabilities is that they can evolve with new information, and the Bayesian school of thoughts provides us with a natural framework to update our beliefs with new information. The space is too limited here to present the theory of subjective probability and its version of expected utility, but we shall attempt to get a glimpse at it by presenting one of the most (if not the most) famous thought experiments that refreshed and ignited research interest in this domain.\n\nThere are several versions of this paradox. One of such is the following. In this experiment, Ellsberg presents the subjects with an urn containing 90 balls, 30\nof which are known to be red, the remaining 60 balls are black or yellow in unknown proportion. The experiment consists of two parts:\n\n1. A ball is randomly drawn from the urn. Subjects are asked to bet on the color of the ball, choosing between on red and black. The ball is then returned to the urn.\n\n2. A ball is drawn randomly from the same urn. Subjects are asked to choose between two choices again, but now between red or yellow and black or yellow. \n\nSuppose that betting correctly would result in \\$1000 prize. How would you make your choice in the first part, and in the second part of the experiment?\n\nIn the first part of the experiment, most subjects prefer betting on red. In the second part, most prefer betting on black or yellow. This is paradoxical because choosing red in the first experiment implies that their subjective probability of the ball being black, $P(B)$ is less than $1/3,$ the objectively (known) probability of the ball being red. This implies that their subjective probability of the ball being yellow, $P(Y),$ is greater than $1/3.$ On the other hand the probability of the ball being black or yellow is $P(B\\cup Y)=2/3,$ whereas $P(R\\cup Y)=P(R)+P(Y)=1/3+P(Y).$ Betting on black or yellow in the second part would imply $P(Y)<1/3,$ contradicting the subjective evaluation of the same individual in the first part. One explanation for this behavior is _ambiguity aversion_, which leads individuals to prefer situations with known odds. \n\nThe literature on ambiguity aversion is extensive and growing. Seminal works include the maximin expected utility model (MEU) of Gilboa and Smeidler (1989), the smooth ambiguity aversion model of Klibanoff et al. (2005,2009), to name just a few.\n\n\n# Exercises\n\n::: {#exr-exoRP}\nCreate a plot similar to @fig-CEandRP for the cases where $u$ is convex and linear. What are the CE and RP in each case?\n:::\n\n::: {#exr-exoCoefRa}\nProve that the Arrow-Pratt coefficient of absolute risk aversion defined in ([-@eq-coefARA]) is invariant to a positive linear transformation. \n:::\n\n::: {#exr-MVutility}\nConsider again the mean-variance utility function in @exm-MVutility. \n\n1. Show that it exhibits decreasing absolute risk aversion. \n2. Consider a decision maker with initial wealth $w$ deciding on the proportion of wealth $\\alpha\\in[0,1]$ to invest in a risky asset $X$ with mean and standard deviation $\\mu_X$ and $\\sigma_X,$ respectively. What is the value of $\\alpha$ that maximizes the expected utility of the decision maker? How does this value change in wealth? Interpret.\n:::\n\n::: {#exr-optInsurance}\n## Optimal insurance demand\n\nConsider an individual with the utility function:\n$$\nu(c, h) = \\ln c - \\frac{L}{h} \\quad L>0,\n$$\nwhere $c$ is his consumption expenditure and $h$ his health insurance expenditure, $L$ is a random variable indicating monetary loss due to sickness. \n    \nFor simplicity, the loss distribution can be described as:\n$$\nL = \\begin{cases}\n1 & \\text{with probability } \\gamma \\in [0,1] \\\\\n0 & \\text{with probability } 1 - \\gamma.\n\\end{cases}\n$$\nThe individual total wealth is $w>0.$\n\nDetermine the optimal consumption and health insurance expenditures. How do they vary in wealth and the probability of sickness?\n:::\n\n    \n\n\n\n\n\n\n\n","srcMarkdownNoYaml":"\n\n\n```{python}\n%load_ext autoreload\n%autoreload 2\n```\n\n```{python}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import cm\nimport seaborn as sns\nimport pandas as pd\nimport dataframe_image as dfi\nimport ipywidgets as widgets\n# from IPython.display import display\n# from ipywidgets import interact\nimport pandas as pd\n```\n\n```{python}\nimport sys\nimport os\nmod_dir = os.path.join(os.getcwd(), 'modules')\nif mod_dir not in sys.path:\n    sys.path.append(mod_dir)\n\nimport micro_modules as mm\nmm.load_viz_settings()\n```\n\n```{python}\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n```\n\nLife abounds with uncertainty, which can be viewed as danger or oppotunities. Pandemics are bad. Wars are bad. But if one has the guts to enter the market during the bear, she will be amply rewarded once it gets to the bull. \nIf there were no uncertainty, there would be no bets. Many games and financial products would not have existed. Investment opportunities range from the high risk type, such as startups, cryptocurrencies, leveraged positions in equity trading to safer ones such as highly rated government bonds. We buy insurance to protect ourselves from the risk of sickness. We save _more_ when we are uncertain about the future. Much of the human evolution has been marked with our species' ingenuity in adapting to and thriving in uncertain environments. Making decisions under uncertainty is often hard, especially when the uncertainty is not quantifiable[^1]. In this chapter, we will be mainly intererested in quantifiable uncertainty or risk, situations in which the decision-maker knows the underlying probability distribution of the random variable of interest (such as future earnings or losses due to sickness). Often times it is hard to make a choice based on pure calculation. Anyone who has ever invested knows that emotion plays no small role in our ability to succeed in a volatile environment.\n\n[^1]: A situation known as ambiguity or Knightian uncertainty. Under ambiguity, unlike under risk, the decision-maker does not know the probability law underlying the random variable of interest. Sometimes in the vernacular, risk is referred to as the _known unknown_ and ambiguity as the _unknown unknown_. Even though they are both uncertainty, ambiguity has been documented to result in higher cognitive load than risk because while risk is processed by the rational powerhouse of our brain, the prefrontal cortex, ambiguity tends to trigger fear and anxiety which are associated with the amygdala in our brain.\n\n# Lotteries\n\nThe simplest way to model an uncertain prospect is by means of a lottery. \n\n::: {#def-lottery}\n## Lottery\nA simple loterry is a list of probabilities over a finite set of consequences or prizes. In particular let $C=\\{c_1,c_2,\\dots,c_N\\}$ be the set of consequences and $p_n$ be the probability that $c_n$ is realized. Then the simple lottery $L$ over the set $C$ is:\n$$\nL = \\{p_1,p_2,\\dots,p_N\\},\n$${#eq-lottery}\n\nwhere $p_i = P(X=c_i)$ satisfying $p_i\\ge 0$ for all $i=1,...,N$ and $\\sum_{i=1}^N p_i = 1.$\n:::\n\n::: {#rem-altDef}\nIn some textbooks a lottery is defined as a list of consequence-probability _pairs_ instead of just a list of probabilities.\n:::\n\nA lottery with $p_i=1$ for some $i$ is called a *degenerated* lottery.\n\n::: {#def-simplex}\n## Simplex\nThe simplex or probability simplex of lotteries, denoted by $\\mathcal{L}$ (or $\\Delta$) is the set of all simple lotteries over a set of outcomes:\n$$\n\\mathcal{L} = \\{p \\geq 0: \\sum_{i=1}^N p_i = 1\\}.\n$$\n:::\n\nSometimes the prizes are lotteries themselves. Lotteries over such prizes are called compound lotteries.\n\n::: {#def-compoundLottery}\n## Compound lottery\nLet $(L_1, L_2, ... L_K)$ be simple lotteries over the same set of prizes (i.e., $L_k\\in \\Delta$ for all $k=1,...,K.$) Let $\\alpha_k$ be the probability of obtaining $L_k.$ Then the compound lottery can be written as:\n$$\n(L_1,L_2,\\dots,L_K;\\alpha_1,\\alpha_2,\\dots,\\alpha_K).\n$$\n:::\n\nNote that any compound lottery can be reduced to a simple lottery:\n$$\nL = \\sum_{k=1}^K \\alpha_k L_k.\n$${#eq-comp_to_red}\n\nAccording to the __consequentialist hypothesis__, only consequences and the probability associated to each consequence matters; the route through which a consequence is obtained is irrelevant. If you have taken a course in probability, you know that this is just the law of total probability. \n\n::: {#fig-compoundLottery fig-cap=\"A compound lottery and its reduced simple lottery\"}\n\n```{python}\n# Initialize figure and axis\nfig, ax = plt.subplots(figsize=(6, 8), nrows=2, ncols=1)\n\n# root\nax[0].scatter(0, 0, color='k', s=75)\n\n# Plot the lines\nax[0].plot([0, 1.5], [0, 1.5], 'k-', lw=3, alpha=.5)  \nax[0].plot([0, 1.5], [0, 0], 'k-', lw=3, alpha=.5)  \nax[0].plot([0, 1.5], [0, -1.5], 'k-', lw=3, alpha=.5) \n\n# Add the text annotations for α and L\nax[0].text(1.55, 1.5, r'$L_1 = (1, 0, 0)$', fontsize=14, ha='left')\nax[0].text(1.55, 0, r'$L_2 = \\left( \\frac{1}{4}, \\frac{3}{8}, \\frac{3}{8} \\right)$', fontsize=14, ha='left')\nax[0].text(1.55, -1.5, r'$L_3 = \\left( \\frac{1}{4}, \\frac{3}{8}, \\frac{3}{8} \\right)$', fontsize=14, ha='left')\n\n# Add the text annotations for α\nax[0].text(0.6, 0.75, r'$\\alpha_1 = \\frac{1}{3}$', fontsize=14, rotation=36, va='bottom',\nha='left')\nax[0].text(0.7, 0.2, r'$\\alpha_2 = \\frac{1}{3}$', fontsize=14, ha='left')\nax[0].text(0.6, -0.75, r'$\\alpha_3 = \\frac{1}{3}$', fontsize=14, va='top', ha='left', rotation=-36)\n\n# Set limits and remove axes\nax[0].set_xlim(-0.1, 2.5)\nax[0].set_ylim(-2, 2)\nax[0].set_title(\"Compound lottery\")\nax[0].axis('off')  # Turn off the axis\n\n\n\n# Second plot\n# root\nax[1].scatter(0, 0, color='k', s=75)\n\n# Plot the lines\nax[1].plot([0, 1.5], [0, 1.5], 'k-', lw=3, alpha=.5)  \nax[1].plot([0, 1.5], [0, 0], 'k-', lw=3, alpha=.5)  \nax[1].plot([0, 1.5], [0, -1.5], 'k-', lw=3, alpha=.5) \n\n# Add the text annotations for α and L\nax[1].text(1.55, 1.5, r'$c_1$', fontsize=14, ha='left')\nax[1].text(1.55, 0, r'$c_2$', fontsize=14, ha='left')\nax[1].text(1.55, -1.5, r'$c_3$', fontsize=14, ha='left')\n\n# Add the text annotations for α\nax[1].text(0.6, 0.75, r'$p_1 = \\frac{1}{2}$', fontsize=14, rotation=36, va='bottom',\nha='left')\nax[1].text(0.7, 0.2, r'$p_2 = \\frac{1}{4}$', fontsize=14, ha='left')\nax[1].text(0.6, -0.75, r'$p_3 = \\frac{1}{4}$', fontsize=14, va='top', ha='left', rotation=-36)\n\n# Set limits and remove axes\nax[1].set_xlim(-0.1, 2.5)\nax[1].set_ylim(-2, 2)\n\nax[1].set_title(\"Reduced (simple) lottery\")\n\n# Show the plot\nplt.axis('off')\nplt.show()\n```\n:::\n\n# Preferences over lotteries\n\nLet $C$ be the set of outcomes (consequences) and $\\mathcal{L}$ the set of all simple lotteries over $C$\n\nA preference relation $\\succeq$ over $\\mathcal{L}$ is said to satisfy:\n\n1. __Completeness__ if for any $L, L' \\in \\mathcal{L}$, either $L\\succeq L'$ or $L'\\succeq L$ or both\n\n2. __Transitivity__ if for any $L, L', L'' \\in \\mathcal{L}$, if $L\\succeq L'$ and $L' \\succeq L''$ then $L\\succeq L''.$\n\n3. __Continuity__ if for $L, L' \\in \\mathcal{L}$ such that $L\\succ L'$, there are neighborhoods $B(L)$ of $L$ and $B(L')$ of $L'$ such that for all $L_a \\in B(L)$ and $L_b \\in B(L')$, the direction of preference is preserved: $L_a \\succ L_b.$ Intuitively, this means that if one strictly prefers a lottery to another, then a slight modification of the lotteries will not alter her ranking.\n\n4. __Independence axiom (IA)__ if for any $L, L', L'' \\in \\mathcal{L}$ and $\\alpha \\in (0,1)$:\n    $$\n    L\\succeq L' \\iff \\alpha L + (1-\\alpha)L'' \\succeq \\alpha L' + (1-\\alpha)L''.\n    $${#eq-IA}\n\n    Intuitively, this means that if one prefers a lottery to another then mixing each by the same proportion with a third lottery will not alter the preference ordering.\n\n# Expected utility theory\n\n::: {#def-EU}\n## Expected utility\nThe utility function $U:\\mathcal{L} \\to \\mathbb{R}$ has the expected utility form if there exist an assignment of numbers $(u_1, ..., u_N)$ to the $N$ possible outcomes such that for every simple lottery $L=(p_1,..., p_N) \\in \\mathcal{L}$, we have:\n$$\nU(L) = \\sum_{n=1}^N p_n u_n.\n$${#eq-EU_form}\n:::\n\nIn other words, $U$ has an expected utility form if there exists some utility function $u:\\mathbb{R}\\to\\mathbb{R}$ that assigns $u_i$ to each consequence $i$ of the lottery $L.$ If such a representation exists, then $U$ is referred to as the von-Neumann Morgenstern (vNM) utility function. We can then compare lotteries by computing the expected utilities associated with them. When does such a representation exist? \n\n::: {#thm-reprsentation}\n## Representability\nIf a decision-maker's preferences over lotteries satisfy completeness, transitivity, continuity and the independence axiom, then it has an expected utility reprsentation. \n:::\n\nObserve that if an expected utility representation exists, then comparing lotteries is equivalent to comparing expected utilities derived from lotteries.\n\n\nSince $U$ is essentially a mathematical expectation, it is a linear map, i.e., let $(L_1,\\dots,L_K;\\alpha_1,\\dots,\\alpha_K)$ be a compound lottery, then:\n\n$$\nU\\left(\\sum_{k=1}^K L_k\\right) = \\sum_{k=1}^K U(L_k).\n$${#eq-linearity-of-U}\n\nAnother way to see this is to observe that the term inside the brackets on the LHS, by the consequentialist assumption, is a simple lottery:\n\n$$\nL = \\left(\\sum_{k=1}^K \\alpha_k p^k_1, \\sum_{k=1}^K \\alpha_k p^k_2, \\dots, \\sum_{k=1}^K \\alpha_k p^k_N\\right)\n$$\n\nover the set of outcomes $(u_1,u_2,\\cdots,u_N),$ where $p^k_i$ denotes the probability of $u_i$ under lottery $k.$ We can think of $\\sum_{k=1}^K \\alpha_k p^k_i$ as the average probability of $u_i$ across $K$ lotteries ($K$ different scenarii).\n\nWe can then rewrite the LHS as:\n\n$$\nU\\left(\\sum_{k=1}^K \\alpha_k L_k\\right) = U(L) = \\sum_{i=1}^N \\sum_{k=1}^K \\alpha_k p^k_i u_i.\n$${#eq-LHS-temp}\n\nThe RHS of @eq-linearity-of-U can be written as:\n\n$$\n\\sum_{k=1}^K \\alpha_k \\sum_{i=1}^N p^k_i u_i,\n$$\n\nwhich is equivalent to @eq-LHS-temp.\n\nAnother important property of the vNM utility is that it is **cardinal**, i.e., the value of the function $U:\\mathcal{L} \\to \\mathbb{R}$ is not just used for ranking; it also has a meaning. It is thus defined only up to a positive affine transformation, i.e., if $U$ reprsents the preferences $\\succeq$ over the lotteries then so is $aU + b$ for $a>0$ and $b\\in\\mathbb{R}.$ This is in contrast to the ordinal utility function introduced in the first chapter, which is preserved under any positive monotone transformation.\n\n# Indifference curves\n\nHow do indifference curves (IC) look like for preferences over lotteries? They must be **straight lines** and are **parallel** to one another.\n\nWhy straight lines? Suppose $L$ and $L'$ lie on the same IC, i.e., $L \\sim L'.$ By the IA, if we mix $L$ and $L'$ with the same lottery by the same proportion, our preference ranking would remain unchanged. Mathematically for any $\\alpha\\in[0,1]:$\n\n$$\n\\begin{aligned}\nL &\\sim L' \\\\\n\\alpha L + (1-\\alpha)L &\\sim \\alpha L' + (1-\\alpha)L \\\\\nL &\\sim \\alpha L' + (1-\\alpha)L. \n\\end{aligned}\n$$\n\nIn other words, if we fix any two lotteries on the same IC, then any convex combination between them (the line connecting the two lotteries) must lie on the same IC. Since $L$ and $L'$ can be arbitrarily chosen, it follows that an IC must be a straight line. \n\nWhy must ICs be parallel to one another? Suppose by contrast there exist two indifference curves $IC_1$ and $IC_2$ intersecting at some lottery $L.$ Let $L_1$ be a lottery on $IC_1$ and $L_2$ be a lottery on $IC_2$ and WLOG suppose that $U(L_2) > U(L_1).$ Now $L \\in IC_1$ hence $U(L)=U(L_1).$ But $L \\in IC_2$ implying $U(L)=U(L_2) > U(L_1) = U(L),$ a contradiction. Hence no two ICs can intersect.\n\n# Money lotteries\n\nWe now consider a more general space of consequences $C=\\mathbb{R}.$ In other words, the outcomes are a continuous variables. The lottery will thus be the probability law underlying some continuous random variable $X.$ In particular we define money lotteries by means of the cdf of $X,$ that is $F:\\mathbb{R}\\to[0,1]$ defined by:\n\n$$\nF(x) = Pr(X \\leq x), \\quad x \\in \\mathbb{R}.\n$$\n\nFrom probability theory we know that a random variable is characterized by its cdf. The same reduction principle applies to compound lotteries. In particular, let $F_1(x), F_2(x),\\dots,F_K(x)$ be $K$ simple money lotteries, each with probability $\\alpha_k$ of occurence. Then the compound lottery can be represented as:\n$$\nF(x) = \\sum_{k=1}^K \\alpha_k F_k(x).\n$${#eq-compound-money-lot}\n\nWe now consider positive monetary amounts, letting $C=\\mathbb{R}_+.$ The expected utility derived from the lottery $F(x)$ of a decision-maker whose preferences admit an expected utility representation is:\n\n$$\nU(F) \\equiv \\mathbb{E}[u(X)] = \\int u(x) dF(x) = \\int u(x)f(x)dx,\n$${#eq-EU-cont-case}\n\nwhere $f:\\mathbb{R}\\to\\mathbb{R}_+$ is the pdf of $X,$ if it exists (i.e. if the cdf is [absolutely continuous](https://en.wikipedia.org/wiki/Absolute_continuity)), and $u(x)$ is the utility obtained from $x$ dollars. The function $u$ is assumed to be continuous, increasing and bounded.[^2] It is often referred to as the Bernoulli utility function.\n\n[^2]: Boundedness is needed to rule out the St.Petersburg paradox.\n\n::: {#exm-MVutility}\n## Mean-variance utility\nLet $u:\\mathbb{R}_+\\to\\mathbb{R}$ be defined by $u(x)=\\beta x^2 + \\gamma x,$ where $\\gamma >0, \\: \\beta < 0$ and $F$ the cdf of $X.$ Then:\n$$\n\\begin{aligned}\n\\mathbb{E}u(X) = U(F) &= \\int u(x) dF(x) \\\\\n&= \\int(\\beta x^2 + \\gamma x) dF(x) \\\\\n&= \\beta \\int x^2 dF(x) + \\gamma \\int x dF(x) \\\\\n&= \\beta \\sigma^2_X + \\gamma \\mu_x + \\beta \\mu_x^2,\n\\end{aligned}\n$$\n\nwhere $\\sigma^2_X$ and $\\mu_X$ are the variance and mean of $X,$ respectively. Thus the expected utility derived from $X$ depends only on the mean and the variance of $X,$ i.e., only on the first two moments of this random variable.[^3]\n\n[^3]: Observe that this utility function is increasing only for $x \\geq -2\\beta/\\gamma.$\n:::\n\n# Risk preferences\n\n## Three preferences towards risk\n\nLet $X$ be a positive-valued random variable that an individual receives. We say that she is **risk-averse** (or exhibits risk aversion) if:\n\n$$\n\\mathbb{E}[u(X)] \\leq u(\\mathbb{E}[X]).\n$${#eq-RA-def}\n$$\n\\int u(x)dF(x) \\leq u\\left(\\int x dF(x)\\right).\n$${#eq-RA-def2}\n\nIf the inequality ([-@eq-RA-def]) or ([-@eq-RA-def2]) reverts, then the individual is **risk-loving**. If the inequality sign becomes an equality, she is **risk-neutral**. Mathematically, risk aversion is captured by a concave Bernoulli utility function $u$, risk loving by a convex  and risk neutrality by a linear Bernoulli utility function respectively.\n\nIntuitively, someone who dislikes risk would prefer a sure gain equivalent to the mean of a random variable rather than playing the lottery over the outcomes of the random variable. \n\n::: {#exm-risk-aversion}\nConsider a game in which one is proposed two options. In the first option, she can either win nothing or \\$10,000 with equal probabilities (by tossing a fair coin, for example). In the second, she can walk away with \\$5000 for sure. Which option will she choose? If she is (strictly) risk-averse, then she will (strictly) prefer the second. If risk-loving, she will prefer the first. If risk-neutral, she will be indifferent.\n\n::: {#fig-ra-exm fig-cap=\"Choices between lotteries and risk preferences\"}\n:::: {.columns}\n::: {.column width=\"45%\"}\n```{mermaid}\nflowchart TB\n    opt1[Option 1] -- 0.5 --> $10000\n    opt1 -- 0.5 --> $0\n```\n:::\n\n::: {.column width=\"45%\"}\n```{mermaid}\nflowchart TB\n    opt2[Option 2] -- 1 --> $5000\n```\n:::\n::::\n:::\n\n:::\n\n## Certainty equivalent and risk premium\n\nBeing strictly risk averse implies that the individual strictly prefers a sure gain to a lottery of the same mean. By continuity, this implies there exists a smaller sure gain that makes the individual indifferent between this smaller sure gain and the lottery. This amount is called the __certainty equivalent__ of the lottery.\n\n::: {#def-CE}\n## Certainty equivalent\nLet $X$ be a positive-valued continuous random variable with cdf $F:\\mathbb{R}_+\\to [0,1].$ Consider a decision-maker whose risk preferences is represented by continuous, strictly increasing and bounded utility function $u:\\mathbb{R}_+\\to\\mathbb{R}.$ The certainty equivalent of $F$ for this decision-maker is:\n$$\n\\begin{aligned}\nc(u, F) &= u^{-1}\\left(U(F)\\right) \\\\\n&=u^{-1}\\left(\\int u(x) dF(x)\\right).\n\\end{aligned}\n$$\n:::\n\nNote that the CE is monetary amount. Clearly the CE is smaller/equal/greater than the mean of the monetary random variable if the decision-maker is risk-averse/neutral/loving. The difference between the CE and the mean of the random monetary prize is called the __risk premium__, which is positive if and only if the decision-maker is risk-averse.\n\n::: {#def-RP}\n## Risk premium\nThe risk premium is the maxmium amount that a decision maker is willing to pay eliminate risk, i.e., to be indifferent between receving the sure gain equal to the mean prize and the lottery. Mathematically,\n$$\n\\begin{aligned}\nRP(u, F) &= EV - c(u, F) \\\\\n&= \\int x dF(x) - c(F, u) \\\\\n&= \\int x dF(x) - u^{-1}\\left(\\int u(x) dF(x)\\right).\n\\end{aligned}\n$${#eq-riskPrem}\n:::\n\nSometimes we denote the risk premium by $\\pi.$ Let us illustrate these two important concepts graphically.\n\n::: {#fig-CEandRP fig-cap=\"Certainty equivalent and risk premium\"}\n\n```{python}\nfrom matplotlib.patches import FancyArrowPatch\nx = np.linspace(0.05, 20, 250)\nprobs = np.array([1 / 3, 2 / 3])\nprizes = np.array([0.1, 12])\na = 1 / 5\ndef vlines(x, ymax):\n    plt.vlines(x=x, ymin=0, ymax=ymax, linestyle='--', lw=0.5, color='gray')\ndef hlines(y, xmax):\n    plt.hlines(y=y, xmin=-2, xmax=xmax, linestyles='--', lw=0.5, color='gray')\ndef u(x, a):\n    return x ** a\ndef EU(prob, prize):\n    return np.dot(prob, u(prize, a))\ndef CE(u_expected):\n    return u_expected ** (1 / a)\ndef EV(prob, prize):\n    return np.dot(prob, prize)\n# plt.figure(figsize=(5, 4))\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.plot(x, u(x, a), color='k')\nplt.plot(prizes, u(prizes, a), color='gray', linestyle='--', lw=1.5)\nu1, u2 = u(prizes, a)\nev = EV(probs, prizes)\neu = EU(probs, prizes)\nce = CE(eu)\nvlines(x=prizes[0], ymax=u1)\nvlines(x=prizes[1], ymax=u2)\nhlines(y=u1, xmax=prizes[0])\nhlines(y=u2, xmax=prizes[1])\nvlines(x=ev, ymax=u(ev, a))\nhlines(y=eu, xmax=ev)\nhlines(y=u(ev, a), xmax=ev)\nvlines(x=ce, ymax=eu)\n\n# annotations\n# x-axis\nplt.text(prizes[0]*.95, -0.1, '$x_1$')\nplt.text(prizes[1]*.95, -0.1, '$x_2$')\nplt.text(ev*.95, -0.1, '$E[X]$')\nplt.text(ce*.95, -0.1, '$c(u,F)$')\n# y-axis\nplt.text(-3.5, u1, '$u_1$')\nplt.text(-3.5, u2, '$u_2$')\nplt.text(-2.5, eu, '$E[u(X)]$', ha='right')\nplt.text(-2.5, u(ev, a), '$u(E[X])$', ha='right')\n# risk premium\nriskprem = ce - ev\narrow = FancyArrowPatch(\n    posA=(ce, u1/2), posB=(ev, u1/2), arrowstyle='<->',\n    color='red', mutation_scale=10)\nax.add_patch(arrow)\nplt.text((ce + ev)/2, u1/2 * 1.1, 'RP')\n# u(x)\nplt.text(1.25*prizes[1], u2, \"$u(x)$\")\n\nplt.xlim([-2, x.max()])\nplt.ylim([0, u2 * 1.1])\nplt.xlabel('Money', loc='right')\nplt.ylabel('Utility')\nplt.xticks([])\nplt.yticks([])\nplt.show()\n```\n:::\n\n## Measure of risk aversion\n\nThere are two common measures of risk aversion: the (Arrow-Pratt) coefficient of absolute risk aversion and coefficient of relative risk aversion. \n\n::: {#def-ARAandRRA}\n## Absolute and relative risk aversion\nThe Arrow-Pratt coefficient of absolute risk aversion for a decision maker with Bernoulli utility function $u:\\mathbb{R}_+\\to\\mathbb{R}$ is:\n$$\nA(x) = -\\frac{u''(x)}{u'(x)}.\n$${#eq-coefARA}\nThe coefficient of _relative risk aversion_ for the same decision-maker is:\n$$\nR(x) = - \\frac{u''(x)x}{u'(x)}.\n$${#eq-coefRRA}\n:::\n\nWhy don't we just use the convexity of $u,$ namely the second derivative of $u?$ Because this measure has an undesirable property: it is not invariant to a positive linear transformation of $u.$ \n\n::: {#exm-utilityFunctions}\n## CARA utility\nThe following utility satisfies constant absolute risk aversion\n$$\nu(x) = -e^{-ax},\n$${#eq-CARAutility}\nwhere $a>0$ is the coefficient of absolute risk aversion.\n:::\n\n::: {#exm-utilityFunctions}\n## CRRA utility\nThe following utility satisfies constant relative risk aversion\n$$\nu(x) = \\begin{cases}\n    \\frac{x^{1-\\sigma}-1}{1-\\sigma}, & \\sigma \\neq 1 \\\\\n    \\ln (x), & \\sigma = 1.\n\\end{cases}\n$${#eq-CRRAutility}\nThe coefficient of constasnt relative risk aversion is $R(x)=\\sigma.$ Note that the vNM utility function is _homothetic_ if and only if the Bernoulli utility function is satisfies CRRA.\n:::\n\n::: {#fig-cara fig-cap=\"CARA utility function and increasing absolute risk aversion\"}\n```{python}\na = [.25, .5, 2.]\nx = np.linspace(0, 20, 250)\ndef cara(x, a):\n    return -np.exp(-a*x)\n# fig, ax = plt.subplots(figsize=(5, 5))\nfor i in a:\n    plt.plot(x,  cara(x, i), label=f'$A(x)=a={i}$')\nplt.title(r\"$u(x)=-e^{-ax}$\")\nplt.xlabel(\"$x$\")\nplt.ylabel(\"$u(x)$\")\nplt.legend()\nplt.xticks(np.linspace(0, 20, 5))\n# plt.grid(None)\nplt.show()\n```\n:::\n\n# Comparing payoff distributions\n\nThe previous section compares different attitudes towards risk (uncertain payoffs). We now compare distributions of payoff (lotteries) using the concept of __stochastic dominance__.\n\n## First order stochastic dominance (FOSD)\n\n::: {#def-FSD}\n## FOSD\nLottery $F$ is said to first order stochastically dominate (FOSD) lottery $G$ if for all payoff $x$:\n$$\nF(x) \\leq G(x).\n$$\n:::\n\nIntuitively, the stochastically dominant lottery concentrates more probability weight on higher payoff values. Graphically, $F$ FOSD $G$ if $F$ is below $G$. \n\n::: {#exm-FSD}\nSuppose $X\\sim U(0,1)$ and $Y\\sim U(0,2).$ Denote the cdf of $X$ by $F_X$ and the cdf of $Y$ by $F_Y.$ Then $F_Y$ FOSD $F_X.$ Indeed, the cdf of a $U(a,b)$ random variable is given by:\n$$\nF(x) = \\begin{cases}\n    0 & x < a \\\\\n    \\frac{x - a}{b - a} & x \\in [a, b] \\\\\n    1 & x > b.\n\\end{cases}\n$${#eq-Ucdf}\nHence\n$$\nF_X(x) = \\begin{cases}\n    0 & x < 0 \\\\\n    x & x \\in [0, 1] \\\\\n    1 & x > 1.\n\\end{cases}\n$$\nand\n$$\nF_Y(x) = \\begin{cases}\n    0 & x < 0 \\\\\n    \\frac{x}{2} & x \\in [0, 2] \\\\\n    1 & x > 2.\n\\end{cases}\n$$\n\nClearly $F_Y(x) \\leq F_X(x)$ for all $x,$ implying that $F_Y$ FOSD $F_X.$\n\n::: {#fig-FSDUnif fig-cap=\"FOSD of $U(0,2)$ over $U(0,1)$\"}\n```{python}\nx = np.linspace(0, 1, 100)\ny = np.linspace(0, 2, 100)\ndef Fx(x, a, b):\n    return (x - a) / (b - a)\ndef plotcdf(x, a, b, color, alpha=.5, lw=2):\n    cdf_vals = Fx(x, a, b)\n    plt.plot(x, Fx(x, a, b), color=color, lw=lw, label=f'U({a},{b})', alpha=alpha)\n    plt.hlines(y=1, xmin=b, xmax=3, color=color, lw=lw, alpha=alpha)\n    plt.hlines(y=0, xmin=-2, xmax=a, color=color, lw=lw, alpha=alpha)\n    plt.legend()\n# plt.figure(figsize=(5, 5))\nplotcdf(x, 0, 1, 'k', lw=3.5)\nplotcdf(y, 0, 2, 'red', lw=3)\nplt.grid(None)\nplt.show()\n```\n:::\n:::\n\n## Second order stochastic dominance (SOSD)\n::: {#def-SOSD}\n## SOSD\nLottery $F$ is said to second order stochastically dominate lottery $G,$ denoted $F$ SOSD $G,$ if they have the same mean and for every nondecreasing concave utility function $u:\\mathbb{R}\\to\\mathbb{R},$ the expected utility under $F$ is greater than that under $G.$ Mathematically:\n\n$$\n\\begin{aligned}\n\\mathbb{E}_F[X] &= \\mathbb{E}_G[X], \\\\\n\\mathbb{E}_F [u(X)] &\\geq \\mathbb{E}_G[u(X)].\n\\end{aligned}\n$$\nor equivalently:\n$$\n\\begin{aligned}\n\\int x dF(x) &= \\int x dG(x), \\\\\n\\int u(x) dF(x) &\\geq \\int u(x) dG(x).\n\\end{aligned}\n$$\n:::\n\n::: {#rem-SOSD-inv-rule}\nNote that the inequality condition in @def-SOSD can be shown to be equivalent to:\n$$\n\\int_a^x [G(t) - F(t)]dt \\geq 0,\\quad x \\in [a,b].\n$${#eq-SOSD-alt-cond}\n:::\n\n::: {#exm-SOSD}\n## Mean-preserving spread\nConsider again two random payoffs $X$ and $Y$ where $X\\sim U(a,b)$ and $Y\\sim U(a-\\epsilon,b+\\epsilon),$ where $b>a>0$ and $\\epsilon >0.$ Observe that both $X$ and $Y$ have the same mean equal to $(b-a)/2$ but the distribution of $Y$ is more spread out about the mean compared to that of $X.$ We say that the distribution of $Y$ is obtained by a mean-preserving spread of the distribution of $X,$ hence is riskier. Let us show that $F_X$ SOSD $F_Y.$ Denote $f_X$ and $f_Y$ the pdfs of $X$ and $Y,$ respectively. Note that:\n$$\n\\begin{aligned}\nf_X(x) &= \\frac{1}{b-a}\\mathbb{1}_{x\\in[a,b]}, \\\\\nf_Y(x) &= \\frac{1}{b-a+2\\epsilon}\\mathbb{1}_{x\\in[a-\\epsilon,b+\\epsilon]},\n\\end{aligned}\n$$\nwhere $\\mathbb{1}_{x\\in[c,d]}$ is an indicator function taking value of one if $x\\in[c,d]$ and zero otherwise. \nIt is easy to check that the cdfs of $X$ and $Y$ can be written as follows:\n$$\nF_X(x) = \\begin{cases}\n    0 & x < a \\\\\n    \\frac{x-a}{b-a} & x \\in [a, b] \\\\\n    1 & x > b.\n\\end{cases}\n$$\nand\n$$\nF_Y(x) = \\begin{cases}\n    0 & x < a-\\epsilon \\\\\n    \\frac{x-a+\\epsilon}{b-a+2\\epsilon} & x \\in [a-\\epsilon,b+\\epsilon] \\\\\n    1 & x > b+\\epsilon.\n\\end{cases}\n$$\nWe will be proving SOSD using ([-@eq-SOSD-alt-cond]). In particular, we only need to verify this condition for $x\\in[a,b],$ namely:\n$$\n\\int_{a}^x [F_Y(t) - F_X(t)] dt \\geq 0,\\quad \\forall x\\in[a,b].\n$$\nIndeed:\n$$\n\\begin{aligned}\nF_Y(t) - F_X(t) &= \\frac{x-a-\\epsilon}{b-a+2\\epsilon} - \\frac{x-a}{b-a} \\\\\n&=\\frac{\\epsilon (a+b-2t)}{(b-a+2\\epsilon)(b-a)} \\\\\n\\implies \\int_{a}^x [F_Y(t) - F_X(t)] dt &= \\frac{\\epsilon}{(b-a+2\\epsilon)(b-a)}\\left[(a+b)x - x^2\\right]_a^x \\\\\n&= \\frac{\\epsilon}{(b-a+2\\epsilon)(b-a)}(x-a)(b-x) \\\\\n&\\geq 0,\n\\end{aligned}\n$$\nwhere the last inequality holds strictly for $x\\in(a,b).$\n:::\n\n## Other measures of stochastic dominance\n\nLet $X$ be a random variable (such as monetary payoffs). Let $F$ and $G$ are two cdfs over the support of $X$. Suppose also that the pdf associated with $F$ and $G$ exist and are denoted by $f$ and $g,$ respectively.\n\n### Hazard rate dominance (HRD)\n\nThe hazard rate of a lottery $F$ is given by:\n\n$$\nHR_F(x) = \\frac{f(x)}{1 - F(x)}.\n$${#eq-hazard-rate}\n\nIntuitively, the hazard rate is the conditional density of $X$ given the probability of the payoff exceeding $x.$\n\nWe say that $F$ dominates $G$ in terms of the hazard rate if:\n\n$$\nHR_F(x) \\leq HR_G(x), \\quad \\forall x.\n$${#eq-hazard-rate-dom}\n\n::: {#exr-HRD}\nShow that HRD implies FOSD.\n:::\n\n### Reverse hazard rate dominance (RHRD)\n\nThe reverse hazard rate of a lottery $F$ is given by:\n\n$$\nRHR_F(x) = \\frac{f(x)}{F(x)}.\n$${#eq-rev-hazard-rate}\n\nIntuitively, the reverse hazard rate is the conditional density of $X$ given the probability of the payoff being less than $x.$\n\nWe say that $F$ dominates $G$ in terms of the reverse hazard rate if:\n\n$$\nHR_F(x) \\geq HR_G(x), \\quad \\forall x.\n$${#eq-rev-hazard-rate-dom}\n\n::: {#exr-RHRD}\nShow that RHRD implies FOSD.\n:::\n\n### Likelihood ration dominance (LRD)\n\nWe say that $F$ dominates $G$ in terms of the likelihood ratio if:\n\n$$\n\\frac{f(x)}{g(x)} \\leq \\frac{f(y)}{g(y)}, \\quad \\forall x < y.\n$${#eq-LRD}\n\n::: {#exr-LRD}\nShow that LRD implies HRD.\n:::\n\nHence LRD is a very strong notion of stochastic dominance, it implies HRD which in turn implies FOSD.\n\n# Paradoxes and alternative theories\n\n## Allais's paradox \n\nThe Allais's paradox illustrates the violation of the independence axiom (IA).\nConsider the set of prizes $C=\\{\\$2.5M, \\$0.5M, 0\\}$ and two lotteries over $C:$\n$$\nL_1 = (0, 1, 0), \\quad L_1'=\\left(\\frac{10}{100}, \\frac{89}{100}, \\frac{1}{100}\\right).\n$${#eq-allais_choice1}\n    \nMost respondents in controlled experiments will choose $L_1,$ which gives a sure prize of 0.5M:\n$$\nL_1 \\succ L_1'\\iff u_{0.5} > \\frac{10}{100}u_{2.5} + \\frac{89}{100}u_{0.5} + \\frac{1}{100}u_{0}.\n$${#eq-allais_1}\n    \n    \nNow consider the same set of outcomes but two other lotteries: \n$$\nL_2=\\left(0, \\frac{11}{100}, \\frac{89}{100}\\right), \\quad \nL_2'=\\left(\\frac{10}{100}, 0, \\frac{90}{100}\\right).\n$${#eq-allais_choice2}\n\nMost people strictly prefer $L_2'$ over $L_2.$\nBy the IA if we add $\\frac{89}{100}u_0 - \\frac{89}{100}u_{0.5}$ to both sides of @eq-allais_1 we should preserve the direction of the inequality, this yields:\n$$\n\\frac{11}{100}u_{0.5} + \\frac{89}{100}u_{0} > \\frac{10}{100}u_{5} + \\frac{90}{100}u_{0}.\n$$  \nBut a strict preference of $L_2'$ over $L_2$ implies:\n$$\\frac{10}{100}u_{5} + \\frac{90}{100}u_{0} > \\frac{11}{100}u_{0.5} + \\frac{89}{100}u_{0}, \n$$\na contradiction.\n\nOne explanation for this paradox is the unrealistic values of probabilities presented, which are close to one or zero and hence are rarely encountered in practice. Another justification comes from _regret theory_, according to which individuals do not wish to regret a sure win.\n\n## Ellsberg's paradox and ambiguity aversion\n\nIn real life situations, we often have to form some probabilistic judgement while making a decision. In tossing a fair coin, we know that the probability of obtaining either results is one half. But in predicting the probability of a presidential candidate winning, we often need to form some subjective evaluation. One nice thing about subjective probabilities is that they can evolve with new information, and the Bayesian school of thoughts provides us with a natural framework to update our beliefs with new information. The space is too limited here to present the theory of subjective probability and its version of expected utility, but we shall attempt to get a glimpse at it by presenting one of the most (if not the most) famous thought experiments that refreshed and ignited research interest in this domain.\n\nThere are several versions of this paradox. One of such is the following. In this experiment, Ellsberg presents the subjects with an urn containing 90 balls, 30\nof which are known to be red, the remaining 60 balls are black or yellow in unknown proportion. The experiment consists of two parts:\n\n1. A ball is randomly drawn from the urn. Subjects are asked to bet on the color of the ball, choosing between on red and black. The ball is then returned to the urn.\n\n2. A ball is drawn randomly from the same urn. Subjects are asked to choose between two choices again, but now between red or yellow and black or yellow. \n\nSuppose that betting correctly would result in \\$1000 prize. How would you make your choice in the first part, and in the second part of the experiment?\n\nIn the first part of the experiment, most subjects prefer betting on red. In the second part, most prefer betting on black or yellow. This is paradoxical because choosing red in the first experiment implies that their subjective probability of the ball being black, $P(B)$ is less than $1/3,$ the objectively (known) probability of the ball being red. This implies that their subjective probability of the ball being yellow, $P(Y),$ is greater than $1/3.$ On the other hand the probability of the ball being black or yellow is $P(B\\cup Y)=2/3,$ whereas $P(R\\cup Y)=P(R)+P(Y)=1/3+P(Y).$ Betting on black or yellow in the second part would imply $P(Y)<1/3,$ contradicting the subjective evaluation of the same individual in the first part. One explanation for this behavior is _ambiguity aversion_, which leads individuals to prefer situations with known odds. \n\nThe literature on ambiguity aversion is extensive and growing. Seminal works include the maximin expected utility model (MEU) of Gilboa and Smeidler (1989), the smooth ambiguity aversion model of Klibanoff et al. (2005,2009), to name just a few.\n\n\n# Exercises\n\n::: {#exr-exoRP}\nCreate a plot similar to @fig-CEandRP for the cases where $u$ is convex and linear. What are the CE and RP in each case?\n:::\n\n::: {#exr-exoCoefRa}\nProve that the Arrow-Pratt coefficient of absolute risk aversion defined in ([-@eq-coefARA]) is invariant to a positive linear transformation. \n:::\n\n::: {#exr-MVutility}\nConsider again the mean-variance utility function in @exm-MVutility. \n\n1. Show that it exhibits decreasing absolute risk aversion. \n2. Consider a decision maker with initial wealth $w$ deciding on the proportion of wealth $\\alpha\\in[0,1]$ to invest in a risky asset $X$ with mean and standard deviation $\\mu_X$ and $\\sigma_X,$ respectively. What is the value of $\\alpha$ that maximizes the expected utility of the decision maker? How does this value change in wealth? Interpret.\n:::\n\n::: {#exr-optInsurance}\n## Optimal insurance demand\n\nConsider an individual with the utility function:\n$$\nu(c, h) = \\ln c - \\frac{L}{h} \\quad L>0,\n$$\nwhere $c$ is his consumption expenditure and $h$ his health insurance expenditure, $L$ is a random variable indicating monetary loss due to sickness. \n    \nFor simplicity, the loss distribution can be described as:\n$$\nL = \\begin{cases}\n1 & \\text{with probability } \\gamma \\in [0,1] \\\\\n0 & \\text{with probability } 1 - \\gamma.\n\\end{cases}\n$$\nThe individual total wealth is $w>0.$\n\nDetermine the optimal consumption and health insurance expenditures. How do they vary in wealth and the probability of sickness?\n:::\n\n    \n\n\n\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"toc-depth":3,"number-sections":true,"output-file":"lecture_6.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.56","theme":{"light":"lux","dark":"darkly"},"mermaid":{"theme":"neutral"},"title":"Chapter 6. Decision making under uncertainty","author":{"name":"My Dam","email":"my-thi-tra.dam@universite-paris-saclay.fr"},"toc-title":"Content","toc-location":"left"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}